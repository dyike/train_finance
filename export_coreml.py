# export_coreml.py  â€”â€” TS-friendly åŒ…è£… + trace + CoreML è½¬æ¢ï¼ˆCPUï¼Œæ›´ç¨³ï¼‰
import torch
import coremltools as ct
from pathlib import Path
from transformers import AutoModelForTokenClassification, AutoTokenizer

MODEL_DIR = Path("./merged_model")
TOKENIZER_DIR = Path("./lora_adapter")
OUT_PATH = Path("coreml_model.mlpackage")

print("ðŸ”¹ Loading HF model:", MODEL_DIR)
model = AutoModelForTokenClassification.from_pretrained(MODEL_DIR)
tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_DIR)

# ---- å…³é”®ï¼šåŒ…è£…æˆ TS å‹å¥½çš„ Moduleï¼Œé¿å… dict / **kwargs ----
class TSWrapper(torch.nn.Module):
    def __init__(self, m):
        super().__init__()
        self.m = m

    def forward(self, input_ids: torch.LongTensor, attention_mask: torch.LongTensor):
        # return_dict=False ä¼šè¿”å›ž tupleï¼Œä½ç½® 0 æ˜¯ logits
        logits = self.m(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)[0]
        return logits.float()  # æ˜Žç¡®æˆ float32ï¼Œé¿å… dtype å…¼å®¹é—®é¢˜

model.eval()
wrapper = TSWrapper(model)

# ---- ç”¨ CPU trace æ›´ç¨³ï¼ˆé¿å… MPS trace å¡ä½ï¼‰----
device = torch.device("cpu")
wrapper.to(device)

# æž„é€ ç¨³å®šç¤ºä¾‹è¾“å…¥
text = "æ˜¨å¤©æ˜Ÿå·´å…‹èŠ±äº†36å…ƒä¹°å’–å•¡"
example = tokenizer(text, return_tensors="pt", padding="max_length", truncation=True, max_length=64)
input_ids = example["input_ids"].to(device)
attention_mask = example["attention_mask"].to(device)

print("ðŸ”¹ Sanity forward:", wrapper(input_ids, attention_mask).shape)

print("ðŸ”¹ Tracing TorchScript ...")
with torch.no_grad():
    traced = torch.jit.trace(wrapper, (input_ids, attention_mask), strict=False)
print("âœ… trace ok")

# ---- Core ML è½¬æ¢ ----
print("ðŸ”¹ Converting to CoreML ...")
mlmodel = ct.convert(
    traced,
    inputs=[
        ct.TensorType(name="input_ids", shape=input_ids.shape, dtype=int),
        ct.TensorType(name="attention_mask", shape=attention_mask.shape, dtype=int),
    ],
    convert_to="mlprogram",
    compute_units=ct.ComputeUnit.CPU_AND_NE,  # å…ˆç”¨ CPU+NEï¼Œå…¼å®¹æ€§æ›´å¥½ï¼›éœ€è¦å¯æ”¹ .ALL
    minimum_deployment_target=ct.target.iOS17,
    compute_precision=ct.precision.FLOAT16,   # è‹¥é‡åˆ°ä¸å…¼å®¹å¯æ”¹æˆ FLOAT32
)
mlmodel.save(OUT_PATH)
print(f"âœ… CoreML model saved -> {OUT_PATH.resolve()}")
